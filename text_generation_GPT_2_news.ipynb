{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_generation_GPT-2_news.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spatiebalk/text_mining_project/blob/master/text_generation_GPT_2_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: November 10th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa33342-7a51-4b4a-9c0b-9848192f2fc3"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115ba047-521d-4066-f0c7-e61c7270285d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Dec 30 08:44:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2611fb-b610-4b6e-954e-8e20f1f71c96"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 543Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 76.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 334Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:01, 254Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 549Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 165Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 224Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ee192a-bc8e-4a87-af01-9e69e0c2612b"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"harrypotter.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b13703-d236-40cb-f500-2f0ab14e9628"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=50,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:07<00:00,  7.93s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1579909 tokens\n",
            "Training...\n",
            "[50 | 69.31] loss=2.89 avg=2.89\n",
            "[100 | 131.89] loss=3.14 avg=3.02\n",
            "[150 | 194.38] loss=3.07 avg=3.03\n",
            "[200 | 256.88] loss=2.83 avg=2.98\n",
            "======== SAMPLE 1 ========\n",
            " tried again, Harry. You were in the end, and now you're not.\"\n",
            "He glanced at her again. She was in tears: she didn't know what she was crying about, but it looked like a very bad time to end a weekend as usual at the Ministry. Ron stood up and looked up. The boy looked shocked, his face a dark pall as though it had never been seen before. He looked very concerned, and Harry could tell he was trying to hide an expression of fear inside. Then he said, in a whisper, \"It's true\" and he burst into laughter.\n",
            "\"Yes, yes, yes, I know,\" said Mrs. Weasley, looking upset. \"But I told you . . . I'm sure you know. . . . Why wouldn't it be for you, when you've been caught? Why couldn't you let the Order of the Phoenix -- how they've done it?\"\n",
            "Harry stared at her and he realized that she was trembling. He wanted nothing more than to cry, he was too busy with his new job, to notice what she was feeling. He tried to think of a way of avoiding her gaze, but she looked back at him.\n",
            "\"But she's a bit confused,\" she said. \"You did this?\"\n",
            "\"I do,\" said Harry, \"so I'll try.\"\n",
            "She looked up again. His smile was so happy.\n",
            "\"Oh, I'm glad you all were okay,\" she told him. \"I'll be with you when you're in the hospital wing . . .\"\n",
            "Mr. and Mrs. Matic went on.\n",
            "\"Well then,\" said Matic, the Slytherin Wizard who had been keeping an eye on Harry, \"do you wish someone from Slytherin would just say yes?\"\n",
            "\"Yeah, yeah, good,\" said Mrs. Weasley. At the end of the class she asked the next Slytherin how they had felt.\n",
            "\"I don't know,\" said Professor McGonagall, \"and we wouldn't know, because we hadn't seen each other in ages.\n",
            "The Gryffindor\n",
            "\n",
            "It would be very difficult to give Professor Trelawney any trouble again with\n",
            "him, except perhaps at Hogwarts - and there was a lot of talk about the Slytherin Tournament,\n",
            "but none of it proved highly satisfactory; Harry, who was not fond of Slytherin and hadn't been told\n",
            "anything, looked on, and saw that the Slytherin team had won it.\n",
            "\"What did that matter?\"\n",
            "\"A lot of the talk now,\" said Harry, \"is about the tournament, the Slytherin team. Who are you going to keep an eye on?\"\n",
            "Professor McGonagall looked at them and nodded.\n",
            "\"I'm afraid not,\" said Professor McGonagall, who was leaning against the wall and her face was hidden, \"because we've been watching it -- you know what you're trying to do, aren't you, the Slytherin team? I know one Slytherin who's here already, a girl who's been in Slytherin for a while, and she's the referee for the Quidditch match, but she was at the end of the class, because she couldn't see that Slytherin player she was supposed to be watching.\n",
            "\"I'm afraid not,\" she repeated. \"Professor Dumbledore's trying to make a case for the Slytherin team. A few of the others didn't want to let it all go, because it looked as though they'd never get back and so they'll have to wait. And then there's the whole Slytherin thing, with everything Slytherin has done at the end of yesterday -- Harry Potter is supposed to leave the Slytherin team, but it really does look more like a team of Slytherins than a team of Slytherins.\"\n",
            "\"I -- just wanted to say, all right, all right, but I think it'd be better if you all knew what we were all watching, you know what you wanted?\"\n",
            "Harry couldn't bear to lie down in the corridor with Professor McGonagall and the Slytherin team. He had to keep staring at them, trying not to think about it, because it was impossible, and he was sure it would all be the same.\n",
            "\"Professor\n",
            "\n",
            "\"Are you with us?\" he said. \"You think you're going to leave, don't you?\"\n",
            "\"I don't think so,\" said said Professor McGonagall. \"You know how easy it is being in the dark here ... even if -- well, I don't think you'd need an excuse.\"\n",
            "Harry stared and he got more angry. Professor McGonagall and the Slytherin and Black teams had been so close this afternoon ... it didn't make any sense - he couldn't hold it back, he just needed to tell her. She was still so shocked that she didn't laugh.\n",
            "\"Well\n",
            "\n",
            "[250 | 329.81] loss=2.76 avg=2.94\n",
            "[300 | 392.30] loss=2.65 avg=2.89\n",
            "[350 | 454.85] loss=2.71 avg=2.86\n",
            "[400 | 517.38] loss=2.66 avg=2.84\n",
            "======== SAMPLE 1 ========\n",
            " supermarket ­\n",
            "but if\n",
            "I'll be at Harry ­ Ron ­ Hermione ­\n",
            "\"He thinks he's his father, too!\"\n",
            "\"How can he be his father, then, if he's the one\n",
            "whose father was born in Ireland?\" said Hermione.\n",
            "And she pointed to Professor Trelawney.\n",
            "\"And if it was you, Professor, why were you here?\"\n",
            "\"Because you knew ­ you knew the place,\" said Hermione.\n",
            "They pulled down the Hogwarts Express and left, looking extremely miserable. Harry was not supposed to be in the\n",
            "country. He had been there for four weeks, and had not looked back ­ except to see that the Hogwarts Express had been turned into a giant\n",
            "rooster, a giant eagle, a horse, an eagle, a unicorn with wings ­ all from the place he had been taken there, but to his enormous\n",
            "hearing, that there was an entire wizarding school here. Harry didn't\n",
            "know what these things were ­ he only knew that the school was enormous, full of wizards, witches, and wizards\n",
            "with great looks and great brains, and a lot of food on the school roof.\n",
            "They had passed the Ministry of Magic, where a group of wizards, witches, and wizards had been celebrating\n",
            "the birthday of the man who had lived on the Hogwarts\n",
            "shores with them.\n",
            "One of the Wizarding Priests was at the entrance ­ he had just returned by this time, the\n",
            "glasses now shining behind him as he watched the wizarding wizards go out into the grounds.\n",
            "\"Here,\" Harry said, looking around.\n",
            "The Hogwarts Express was already on its way home, and this was nothing compared to\n",
            "this. Harry was not going to wait until it was in for his own reasons, so he looked around. He turned a\n",
            "clockwise to watch it. As it approached the station, the train zoomed down towards the\n",
            "station. Harry did not want to be caught without Ron. He had heard the news that he and Hermione\n",
            "were going to be expelled for the following Thursday, and that they were going\n",
            "to be in Gryffindor House. However, he had hoped to visit Hermione, the only\n",
            "other person in Gryffindor House who could possibly be expelled this week. He had\n",
            "been hoping to leave her house, but it was only after Hermione made one\n",
            "more appearance in the front page of the Times how Harry realized the\n",
            "new Minister of Magic would appear, Ron had come, and they were going to have to wait\n",
            "for him on Sunday at dinner.\n",
            "The Hogwarts Express departed with Harry out of Gryffindor\n",
            "House, Ron and Hermione back inside the carriage, Harry's first impression was that Harry\n",
            "had simply been walking on a snowy day. The train was rolling up and down the\n",
            "road at high speed, and Harry knew that it would be very difficult to move to\n",
            "stop it as it moved, and Harry knew it would be dangerous to turn back to get Harry. The\n",
            "way to Hogwarts was very quiet; Harry had only passed the entrance doors\n",
            "where the wizarding students had stood for the first time. As he drew closer he saw Harry\n",
            "shaken but still watching the train as the conductor turned sharply off the\n",
            "centre. \"That carriage will be used up in just ten minutes,\" he said, and he\n",
            "continued, \"and then we can take the train back to the castle for dinner ­\"\n",
            "He didn't understand how that could have been possible. He looked around at Ginny, but\n",
            "he had no idea the corridor was deserted. He and Hermione both jumped\n",
            "out of bed together.\n",
            "\"It's your fault!\" Harry mumbled.\n",
            "\"But my wife and I couldn't make it,\" said Hermione firmly. She was still still asleep at\n",
            "the same moment.\n",
            "\"Sorry to spoil you,\" said Harry, not looking at her. \"But we'll see if we can persuade Professor, and she ­ I haven't\n",
            "had the nerve.\"\n",
            "\"You wouldn't do something like that without permission from the Minister,\" said Ron.\n",
            "\"Yeah, okay,\" said Hermione, looking slightly embarrassed ­ she gave Harry a look of her utmost\n",
            "belief, a kind of look that she might have looked at a witch standing alone in a\n",
            "pupil's bathroom.\n",
            "He knew that, as she walked away, he and Hermione were going to have to stand up\n",
            "again, take a break from their breakfast, and then go for an evening out of\n",
            "Hermione, who had been the only person there. He got to his feet. And then\n",
            "Hermione said quietly, \"Oh, Hermione.\"\n",
            "His mind was working properly, but he could not see anything to make sense of. If the Deathly Hallows had been\n",
            "an open secret, what were the consequences of what Harry was\n",
            "telling him? What if he had been charged with the crimes that had been committed\n",
            "under the name of Hedwig?\n",
            "\n",
            "\n",
            "[450 | 589.14] loss=2.56 avg=2.80\n",
            "[500 | 651.67] loss=2.50 avg=2.77\n",
            "Saving checkpoint/run1/model-500\n",
            "[550 | 716.81] loss=2.56 avg=2.75\n",
            "[600 | 779.37] loss=2.83 avg=2.76\n",
            "======== SAMPLE 1 ========\n",
            " the Ministry and, with the others now facing him, he and Mr.\n",
            "Jordan\n",
            "were forced to face his attackers in the most bizarre circumstances - a duel,\n",
            "he claimed, as he explained how Mr. Weasley had been stabbed to death in\n",
            "hospital.\n",
            "Mr. Weasley, who had been having severe pain in his right hand, had\n",
            "tried to revive him by hitting Mr. Weasley across the head with a staff member on\n",
            "the right side of his head. Mr.\n",
            "Crookshanks, meanwhile, had been knocked unconscious by a stray blow, whose\n",
            "damage had been punctured by one of the Dungbombs.\n",
            "Harry had an unpleasant feeling Mr. Weasley had been right in Mr.\n",
            "Potter's mind about Ron.\n",
            "\"Harry, I think Mr. Weasley's not the only one who thinks this is it,\" said\n",
            "Ginny as they passed him and Harry walked away, clutching at each side of\n",
            "the severed head as though it was a living weapon. \"You and\n",
            "Ron, that could be a real problem.\"\n",
            "Mr. Weasley walked toward them, his face hidden behind a large tangerine hat, as though\n",
            "Hagrid had picked up an enormous leather watch.\n",
            "\"And if he loses control,\" continued Mr. Weasley, with a faint hint of impatience, \"then we will just\n",
            "have to sort out the situation.\"\n",
            "Mr. Jordan took the cloak off. After a little while he said grimly, \"I...\n",
            "hopefully... don't turn into Horntail again.\"\n",
            "A short time later, Harry looked sideways at his handkerchief in the large circular\n",
            "fold on to the shelf.\n",
            "\"What?\" said Ginny heavily, looking at him.\n",
            "\"What?\" said Mr. Harry quietly, turning back to the table and picking up his\n",
            "wizard wand.\n",
            "\"So.\" said Mr. Weasley, pushing the sword back under his cloak. \"But I\n",
            "have the power to turn you into Hoggory - I could turn anyone\n",
            "into it so bad...\"\n",
            "As though hoping to get an unfair advantage, Mr. Weasley turned his eyes from Harry to\n",
            "Ginny.\n",
            "\"But I can also turn you into a dragon.\"\n",
            "The dragon looked slightly happier than usual, his fangs gleaming slightly in\n",
            "the moonlight.\n",
            "\"But that's an extremely simple and clever trick,\" said Mr. Crookshanks, turning his\n",
            "glowing eyes slightly on the empty table and pointing at Harry. \"You can\n",
            "turn anyone.\"\n",
            "\"What are dragons?\" said Mr. Crookshanks.\n",
            "\"You could use 'er own blood and your own magical blood!\" said Mr.\n",
            "Crookshanks, pointing to the large square in the center of the table with the\n",
            "sword.\n",
            "\"That's right,\" said Mr. Weasley, tapping the table's iron surface with his wand.\n",
            "\"But I'm sure we'll win the duel,\" said Mr. Crookshanks, looking from one\n",
            "to the other, and speaking out. He turned Ron's head to stare again.\n",
            "\"I don't think you can do it,\" he said.\n",
            "\"Well . . .\" said Ginny, sounding slightly anxious, \"I'll wait here.\"\n",
            "She took one very good look at the table and said, \"I just hope we win.\"\n",
            "As though Mr. Weasley wanted to argue with her, Mr. Weasley forced his face into a\n",
            "wishful expression.\n",
            "\"It could be a funny argument,\" said Mr. Weasley. \"Because it is, and I can tell\n",
            "you will not let it happen again....\"\n",
            "\"What? If only I had an argument with you, I'd rather not discuss\n",
            "the matter with you! And you are not doing any of the work I've asked you to, so I...\n",
            "\"Harry?\"\n",
            "\"Er...\"\n",
            "\"It's not my fault,\" said Mr. Weasley, who did not look at Ginny.\n",
            "\"No, it's ours. Hermione can't have left us if she keeps her mind on her\n",
            "good self.\"\n",
            "\"You did all right, Hermione! You got her a job, and she won\n",
            "that job, so we've got to do the rest!\"\n",
            "But the conversation had begun. The Hufflepuff table was suddenly crowded\n",
            "enough to keep its occupants' curiosity abating.\n",
            "\"Harry,\" Harry said to Ron, \"if you could have put you in my office, but only\n",
            "because I told you to, and because it's the only place that's fair, and\n",
            "because we need to set aside any pretence that we might lose an Inferius fight and\n",
            "don't have a clue what we're after?\"\n",
            "\"Oh, that's definitely the only place,\" said Hermione timidly.\n",
            "\"You only just won that duel, you can tell us in a word!\" said Ron,\n",
            "sending a glance at Gilderoy Lockley with\n",
            "\n",
            "[650 | 851.49] loss=2.74 avg=2.76\n",
            "[700 | 913.95] loss=2.75 avg=2.76\n",
            "[750 | 976.33] loss=2.67 avg=2.75\n",
            "[800 | 1038.74] loss=2.72 avg=2.75\n",
            "======== SAMPLE 1 ========\n",
            " get to tell you what we've found, just be forewarned. And don't forget, the real wizard is only a wizard by birth,\"\n",
            "Harry finished.\n",
            "\"So. . . the Dark Lord will surely stop at nothing to save the young Lord, and you,\n",
            "Molly, are a wizard by birth. You just have to keep in touch with your father's teachings.\"\n",
            "Molly raised her wand. When she reached the tip of the hat, she pointed her wand at it.\n",
            "\"Your mother was quite sure that Lord Voldemort had been killed, while you were a young, noble lad. Your father was a great wizard himself, which meant... well, you just had to be at least a bit\n",
            "sure of what your father meant by heroism and your mother definitely was the same way. But... but... but...\n",
            "Molly put away her wand, and Harry pulled out his own. Holding her on one hand and his hand\n",
            "waving her wand up in the air with him, he soared from the hat, the darkness in his eyes\n",
            "filled. The only thing he could see was the dark outline of a man, a man\n",
            "who, Harry was sure were alive but not dead, looking very odd, but who was\n",
            "speaking in a whisper.\n",
            "\"You will not kill a man for a mother. Do not kill me, Molly. Do not harm me. Do not do it . . . . kill me. It is not my fault that he has been left, Molly, because he is my husband. I am neither here, nor ever will be, but will leave you alone\" -\n",
            "Molly moved up and down in her seat, not at the proper position, while her seat became slightly more comfortable for her, so she\n",
            "started to sit. Harry watched her as she spoke until she paused to listen, but when she spoke a little more loudly she rose again\n",
            "and sat down. The moment he heard her, he realized how little sympathy she could\n",
            "expect him to feel.\n",
            "\"Are they all right, Molly?\" he asked.\n",
            "\"Yes, all the right,\" she said hoarsely.\n",
            "He sat down, his head in her lap, his voice like a glass of wine, her head in his,\n",
            "he looked away when he hadn't meant to and turned back to him. He walked back to the stone pillar\n",
            "she had opened at the first sign of light and looked around again. No sign of a body, of\n",
            "something moving or hiding. Harry didn't have the strength to look and take in his surroundings.\n",
            "When he had done so, a silence fell around them in the corridor behind the barrier door. Harry,\n",
            "saying no, he pushed his head in his hands and felt his stomach turning. And then he heard the\n",
            "swimming heads of the spiders and the screams of the people around him --\n",
            "\"No! I - I’m not going - I’m not going -\"\n",
            "They were all shouting, screaming. Everyone was screaming. Dumbledore was running down stairs\n",
            "nearly a foot above them.\n",
            "The barrier door did not open. Some people were still fighting. Harry looked around for a sign of a body, but he\n",
            "found nothing. He just looked. He moved from the edge of the corridor and turned; there, on the other side\n",
            "of the barrier, stood a man with great black hair and a long black hat. He walked over to him\n",
            "and lifted him headlong from the floor. The man had long robes, a thin and silky mane of\n",
            "dark gray, with a long black cloak draped around his arms. One eye was\n",
            "serenely shining. It was not human: there were no markings, no scars. All he was\n",
            "looking at was him, his hair tangled and untidy as if all his soul had been wrung out of its\n",
            "breath. His eyes did not move as he stared.\n",
            "\"We're leaving, have you, Molly? Well, I must say, I can't wait anymore. I think I’ve found a way for you to come and have a private moment, I can’t wait.\"\n",
            "\"I...\"\n",
            "\"What's going to happen to you, then if you don't get back?\" gasped Dumbledore.\n",
            "\"Well, if you die, you don't pay to come back, I promise you I can deal with all my own problems,\"\n",
            "said the man. \"You can live with me while I deal with other people... without Sirius --\"\n",
            "\"You don't want that, do you?\" whispered Dumbledore.\n",
            "\"I suppose I do,\" said the man, waving his wand in Dumbledore’s direction. \"The Dark Lord knows none of this to my liking, Molly, and I can deal with it by myself.\"\n",
            "Harry's head was still throbbing as he watched the man walk out of the room.\n",
            "\"How did I know you'd come?\"\n",
            "\"\n",
            "\n",
            "[850 | 1110.18] loss=2.45 avg=2.73\n",
            "[900 | 1172.51] loss=2.54 avg=2.72\n",
            "[950 | 1234.81] loss=2.48 avg=2.70\n",
            "[1000 | 1297.07] loss=2.31 avg=2.68\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "8218f16f-e404-4d8e-a7ae-d4b389657cb3"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-42fe8a91f36d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mload_gpt2\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, multi_gpu)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n\u001b[0;32m--> 183\u001b[0;31m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.01))\n\u001b[0m\u001b[1;32m    184\u001b[0m         wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n\u001b[1;32m    185\u001b[0m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.02))\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3690815c-ed8a-4a9b-e3f1-033403d2a16f"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She stood there, glaring at him and looking unconvinced.\n",
            "\"Do I look like I've got to go back to the Owlery?\"\n",
            "\"Well, no,\" said Harry uncertainly. \"Not now, I just thought I'd found out more.\"\n",
            "He turned to look at the pair of them, who were standing in front of his own door.\n",
            "\"I'm going back!\" he said. \"I can tell -\"\n",
            "\"You get the point, Harry,\" said Hermione, and she made a small movement in her office toward the door.\n",
            "Harry's heart began to race. He could never have imagined that this place was going to be the place he had wanted to go to in life. . . .\n",
            "\"If I just get inside,\" said Hermione, in a tone of conviction, \"I'll be able to see the place where you come from. . . . I'd really like to go back to my school. . . .\"\n",
            "And he felt a burning, anger­filled desire to leave.\n",
            "Chapter Eight\n",
            "After the Owlery\n",
            "Harry was standing on a very high, flat chair by the fire. He felt as though there was something there, something solid and smooth, something that looked like solid steel. He could see the outlines of the silver footprints in the snow below him, and he could hear the thunder of the fires, the blinks of the broomstick, the whistling of the engine. He turned to Hermione, who was already sitting down on Harry's other side.\n",
            "\"Harry, where did you get this sword? Is it really necessary to go back to the Owlery?\"\n",
            "\"It's a pity,\" said Harry. \"It's a pity we lost you in that Potters cave, isn't it?\"\n",
            "\"Yeah,\" said Hermione.\n",
            "\"Harry, you... you think it's all part of the plan?\"\n",
            "\"Yeah,\" said Harry. \"But I still don't think it's essential, it's just... I don't think I'll be able to go back any more unless I get the sword, so I'll have to find another one.\"\n",
            "\"What's that?\" said Hermione.\n",
            "\"Oh yeah,\" said Harry, \"it's about time, I really don't think I'll be able to go back to Hogwarts... Dumbledore told me to get it, all right, he's gone.\"\n",
            "Hermione looked at him incredulously.\n",
            "\"He's gone?\" she said. \"And you?\"\n",
            "\"Harry, Dumbledore said I'd better hurry up and tell him I'll be able to show him the sword, he said he'd have to explain later.\"\n",
            "\"But he said I'm going to explain later, he's not going to be able to explain... he was just trying to get to my school!\"\n",
            "\"He's got to explain why he lost you in the Potters' cave!\" said Harry.\n",
            "\"So I'll explain later?\" said Hermione. \"Why?\" \"Well, that'll explain, won't it?\" she added, in an awestruck tone.\n",
            "\"Oh no, I don't think I need to explain,\" said Harry. \"I just need to have a clear idea of the situation. I don't know whether I should go back to the Owlery or not.\"\n",
            "\"Can you give me a clear idea?\" said Hermione. \"I've been looking for this sword for years and a half -\"\n",
            "\"It can't be the sword!\" said Harry. \"It can't be the sword!\"\n",
            "\"It's not a sword!\" said Hermione, her voice echoing through the silence. \"It's the sword. It says you've got to go back to the castle, it's not a question of 'I need to go back to the castle,'\" she added, and the silence seemed to be broken by the sound of the sword spinning wildly.\n",
            "\"And you're going to tell me where to go?\" said Harry, aghast.\n",
            "\"I can't tell you where you ought to go,\" said Hermione, frowning at him.\n",
            "\"I won't,\" said Harry.\n",
            "\"No, you won't. You haven't got a clue what you're doing, have you?\"\n",
            "\"Yeah, I've got a clue,\" said Harry, and he looked her up and down. \"I've seen what you've written on the map. I've been wanting to ask you questions all summer, but you're a prefect. The sword's a gift from Godric, it's a good story to tell. He was at Hogwarts when I was a kid, and he's still alive. Come on, Harry, we've got to go and get this sword.\"\n",
            "She dropped her voice and said, \"We're going to go back, we can't go after you unless we get the sword.\"\n",
            "\"It's bound to be the sword,\" said Harry.\n",
            "\"We can't go after it, we can\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N"
      },
      "source": [
        "# open prompts file\n",
        "prompts = open('drive/My Drive/TxMM/hp_prompts.txt', 'r').readlines()\n",
        "generated_dict = {}\n",
        "\n",
        "for i, p in enumerate(prompts):\n",
        "  # generate 1000 characters\n",
        "  gen_text = gpt2.generate(sess, \n",
        "                     length=1000,\n",
        "                     temperature=0.7,\n",
        "                     prefix=p,\n",
        "                     return_as_list=True)[0]\n",
        "\n",
        "  generated_dict[i] = gen_text\n",
        "\n",
        "with open('drive/My Drive/TxMM/GPT-2_results/hp_generated_texts.json', 'w') as fp:\n",
        "  json.dump(generated_dict, fp)\n",
        "\n",
        "# text = gpt2.generate(sess, \n",
        "#                      length=1000,\n",
        "#                      temperature=0.7,\n",
        "#                      prefix=p,\n",
        "#                      return_as_list=True)[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}